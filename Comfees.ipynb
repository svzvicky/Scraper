{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Comfees.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMB3IIBQHDa1lq63ZMQs67i",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svzvicky/Scraper/blob/main/Comfees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6DBcbBUy-H2"
      },
      "source": [
        "import requests\r\n",
        "import pandas as pd\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "\r\n",
        "#Read the URLs from the excel file\r\n",
        "# urls = pd.read_excel('input.xlsx')\r\n",
        "# urls.head()\r\n",
        "# urls = urls_dataframe.values.tolist()\r\n",
        "# urls = [x[0] for x in urls]\r\n",
        "# print(urls)\r\n",
        "\r\n",
        "#Input the URLs here\r\n",
        "urls = []\r\n",
        "\r\n",
        "#Creating to hold the Data extracted\r\n",
        "data = []\r\n",
        "\r\n",
        "for url in urls:\r\n",
        "    response = requests.get(url)\r\n",
        "    soup = BeautifulSoup(response.text)\r\n",
        "    title = soup.title.string\r\n",
        "  \r\n",
        "    metas = soup.find_all('meta')\r\n",
        "    description= (\r\n",
        "        [meta.attrs['content']\r\n",
        "        for meta in metas\r\n",
        "          if 'name' in meta.attrs and meta.attrs['name'] == 'description']\r\n",
        "    )\r\n",
        "\r\n",
        "    temp = [url, title, description]\r\n",
        "    data.append(temp)\r\n",
        "#print(data)\r\n",
        "\r\n",
        "df = pd.DataFrame(data,columns=['URL', 'Title', 'Description'])\r\n",
        "print(df)\r\n",
        "df.to_excel(\"Crawler_Output.xlsx\", sheet_name=\"Output_Data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdGiNbb1PjXj"
      },
      "source": [
        "# Main Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNQFNoxqPnwt"
      },
      "source": [
        "import requests\r\n",
        "import pandas as pd\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "\r\n",
        "#Read the URLs from the excel file\r\n",
        "# urls = pd.read_excel('input.xlsx')\r\n",
        "# urls.head()\r\n",
        "# urls = urls_dataframe.values.tolist()\r\n",
        "# urls = [x[0] for x in urls]\r\n",
        "# print(urls)\r\n",
        "\r\n",
        "#Input the URLs here\r\n",
        "urls = []\r\n",
        "\r\n",
        "#Creating to hold the Data extracted\r\n",
        "data = []\r\n",
        "\r\n",
        "for url in urls:\r\n",
        "    response = requests.get(url)\r\n",
        "    soup = BeautifulSoup(response.text)\r\n",
        "    title = soup.title.string\r\n",
        "  \r\n",
        "    metas = soup.find_all('meta')\r\n",
        "    description= (\r\n",
        "        [meta.attrs['content']\r\n",
        "        for meta in metas\r\n",
        "          if 'name' in meta.attrs and meta.attrs['name'] == 'description']\r\n",
        "    )\r\n",
        "\r\n",
        "    temp = [url, title, description]\r\n",
        "    data.append(temp)\r\n",
        "#print(data)\r\n",
        "\r\n",
        "df = pd.DataFrame(data,columns=['URL', 'Title', 'Description'])\r\n",
        "print(df)\r\n",
        "df.to_excel(\"Crawler_Output.xlsx\", sheet_name=\"Output_Data\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9Sff0QJQA8n"
      },
      "source": [
        "# Learn Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7FujPsfQVRv"
      },
      "source": [
        "import pandas as pd\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "\r\n",
        "#students_grades = pd.read_excel('grades.xlsx')\r\n",
        "#students_grades.head()\r\n",
        "\r\n",
        "# urls = pd.read_excel('Comfees_input.xlsx')\r\n",
        "# urls.head()\r\n",
        "\r\n",
        "urls = pd.read_excel('Input.xlsx')\r\n",
        "urls.head()\r\n",
        "urls = urls_dataframe.values.tolist()\r\n",
        "urls = [x[0] for x in urls]\r\n",
        "print(urls)\r\n",
        "\r\n",
        "for url in urls:\r\n",
        "    response = requests.get(url)\r\n",
        "    soup = BeautifulSoup(response.text)\r\n",
        "    title = soup.title.string\r\n",
        "    print(title)\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}